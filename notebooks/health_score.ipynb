{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a9bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Any, Tuple, Union\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a3caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 658 image/mask triples.\n"
     ]
    }
   ],
   "source": [
    "BASE: Path = Path(\"../bleaching_data_RS\")\n",
    "IMG_DIR: Path = BASE / \"images\"\n",
    "MASKS_BLEACHED_DIR: Path = BASE / \"masks_bleached\"\n",
    "MASKS_UNBLEACHED_DIR: Path = BASE / \"masks_non_bleached\"\n",
    "\n",
    "\n",
    "def find_mask_triple(img_path: Path) -> Union[Tuple[Path, Any, Any], Tuple[Path, None, None]]:\n",
    "    \"\"\"\n",
    "    Group the original and mask image files based on their stem.\n",
    "    The stem is the original file name without the file extension. \n",
    "    As this is the same for all 3 images, it will select them all. \n",
    "\n",
    "    Args:\n",
    "        img_path (Path): file path of an image in the \"images\" folder\n",
    "\n",
    "    Returns:\n",
    "        tuple[Path, Any, Any] | tuple[Path, None, None]: tuple of file paths for all equal images (original + 2 masks)\n",
    "    \"\"\"\n",
    "    image_stem = img_path.stem \n",
    "\n",
    "    bleached_path = MASKS_BLEACHED_DIR / f\"{image_stem}_bleached.png\"\n",
    "    unbleached_path = MASKS_UNBLEACHED_DIR / f\"{image_stem}_non_bleached.png\"\n",
    "    if bleached_path.exists() and unbleached_path.exists(): # Check that all 3 versions of the image are there, and group them\n",
    "        return img_path, bleached_path, unbleached_path\n",
    "    return img_path, None, None\n",
    "\n",
    "# Build the dataset\n",
    "triple: list[Any] = []\n",
    "for img_path in IMG_DIR.glob(\"*.jpg\"):\n",
    "    img_path, bleached_path, non_bleached_path = find_mask_triple(img_path)\n",
    "    if bleached_path is None or non_bleached_path is None:  # Warning if there is a missing mask\n",
    "        print(f\"[WARN] Missing masks for {img_path.name}\")\n",
    "        continue\n",
    "    triple.append((img_path, bleached_path, non_bleached_path))\n",
    "\n",
    "print(f\"Found {len(triple)} image/mask triples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d70a10",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def srgb_to_linear(color_channel_array: npt.NDArray[np.uint8]) -> npt.NDArray[np.float32]:\n",
    "    \"\"\"\n",
    "    To invert the nonlinear scale, a specific formula needs to be applied based on the value of the pixel. \n",
    "    If the value is lower or equal to 0.04045, then the value should be divided by 12.92.\n",
    "    If the value is higher than 0.04045, then v = ((v+0.055) / 1.055) ^ 2.4\n",
    "\n",
    "    Args:\n",
    "        color_channel_array (npt.NDArray[np.uint8]): 2D array of a color channel\n",
    "\n",
    "    Returns:\n",
    "        npt.NDArray[np.float32]: 2D array of the linearized color channel.\n",
    "    \"\"\"\n",
    "    x = color_channel_array.astype(np.float32) / 255.0  # First convert the pixel values to [0,1] scale\n",
    "    return np.where(x <= 0.04045, x / 12.92, ((x + 0.055) / 1.055) ** 2.4).astype(np.float32)\n",
    "\n",
    "def robust_unit(x: np.ndarray, mask: np.ndarray | None) -> np.ndarray:\n",
    "    # Ensure float32\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    H, W = x.shape[:2]\n",
    "\n",
    "    if mask is None:\n",
    "        mask = np.ones((H, W), dtype=bool)\n",
    "    else:\n",
    "        mask = mask.astype(bool, copy=False)\n",
    "        if mask.shape[:2] != (H, W):\n",
    "            mask = np.ones((H, W), dtype=bool)  # last-resort fallback\n",
    "\n",
    "    vals = x[mask]\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "\n",
    "    if vals.size < 4:\n",
    "        base = x[np.isfinite(x)]\n",
    "        if base.size < 4:\n",
    "            return np.zeros_like(x, dtype=np.float32)\n",
    "        p1, p99 = np.percentile(base, [1, 99])\n",
    "    else:\n",
    "        p1, p99 = np.percentile(vals, [1, 99])\n",
    "\n",
    "    # Cast percentiles to float32 to prevent upcasting x to float64\n",
    "    p1  = np.float32(p1)\n",
    "    p99 = np.float32(p99)\n",
    "    denom = np.float32(max(p99 - p1, 1e-6))\n",
    "\n",
    "    # In-place normalize and clip to avoid extra big allocations\n",
    "    y = x.copy()                   # one working buffer\n",
    "    y -= p1                        # in-place\n",
    "    y /= denom                     # in-place\n",
    "    np.clip(y, 0.0, 1.0, out=y)    # in-place\n",
    "    return y\n",
    "\n",
    "def create_all_scores(bgr_img: npt.NDArray[np.uint8], mask_matrix: npt.NDArray[np.bool_]) -> Tuple[Any, Any, Any, Any, Any, Any]:\n",
    "    \"\"\"\n",
    "    Converts an image and its mask into all the visual traits we want to investigate. \n",
    "\n",
    "    Args:\n",
    "        bgr_img (npt.NDArray[np.uint8]): 3D matrix of (HxWxc) with c being the color channel.\n",
    "        mask_matrix (npt.NDArray[np.uint8]): 2D matrix of (HxW).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Any, Any, Any, Any, Any, Any]: A tuple with bgr_GW, LAB_img, raw_red_score, albedo_score, luminance_score, saturation_score.\n",
    "    \"\"\"\n",
    "    # Convert input image to GWWB\n",
    "    b, g, r = cv2.split(bgr_img.astype(np.float32))\n",
    "    mean_b, mean_g, mean_r = b.mean(), g.mean(), r.mean()\n",
    "    mean_value = (mean_b + mean_g + mean_r) / 3\n",
    "    b *= mean_value / (mean_b + 1e-6)\n",
    "    g *= mean_value / (mean_g + 1e-6)\n",
    "    r *= mean_value / (mean_r + 1e-6)\n",
    "    bgr_GW = cv2.merge([b, g, r])\n",
    "    bgr_GW = np.clip(bgr_GW, 0, 255).astype(np.float32)\n",
    "\n",
    "    # Convert sRGB values to a perceptually linear scale, and compute raw-red and albedo scores\n",
    "    bgr_linear = srgb_to_linear(bgr_GW)\n",
    "    sum_linear = bgr_linear.sum(axis=-1)\n",
    "    raw_red_score = (bgr_linear[..., 2] / (sum_linear + 1e-6)) \n",
    "    albedo_score = (sum_linear / 3.0).astype(np.float32)\n",
    "\n",
    "    # Convert the GWWB images to CIELAB, and equalize the luminance using the CLAHE method\n",
    "    LAB_img = cv2.cvtColor(bgr_GW.astype(np.uint8), cv2.COLOR_BGR2LAB) # This function requires the pixel values to be integers.\n",
    "    luminance, a_channel, b_channel = cv2.split(LAB_img)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    L_equalized = clahe.apply(luminance)\n",
    "\n",
    "    # Create luminance and saturation scores, and normalize them to percentiles\n",
    "    luminance_score = L_equalized.astype(np.float32) / 255\n",
    "    a_channel_normalized = a_channel.astype(np.float32) - 128\n",
    "    b_channel_normalized = b_channel.astype(np.float32) - 128\n",
    "    saturation_score = np.sqrt(a_channel_normalized**2 + b_channel_normalized**2)\n",
    "    luminance_score = robust_unit(luminance_score, mask_matrix)\n",
    "    saturation_score = robust_unit(saturation_score, mask_matrix)\n",
    "\n",
    "\n",
    "    return bgr_GW, LAB_img, raw_red_score, albedo_score, luminance_score, saturation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "889c2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ECDFs(path_triples: list[tuple[Path, Path, Path]])-> dict[str, npt.NDArray[np.float32]]: \n",
    "    \"\"\"\n",
    "    For each image in the given dataset, the whiteness score is calculated for the coral pixels.\n",
    "    Outliers (= values outside winsorization range) are clipped. \n",
    "    Then a histogram of the whiteness values is created. \n",
    "    Input setting \"weighting\" decides if all pixels have equal weight, or if all images do.\n",
    "    Then an ECDF is created from all histograms.\n",
    "\n",
    "    Args:\n",
    "        path_triples (list[tuple[Path, Path, Path]]): Paths to the images.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Raise error if empty score array is found.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, npt.NDArray[np.float32]]: Dictionary with bin edges and cdfs of each score.\n",
    "    \"\"\"\n",
    "    # Iterate over all images in the given dataset\n",
    "    for img_path, mb_path, mn_path in path_triples:\n",
    "        img_bgr: npt.NDArray[np.uint8] = cv2.imread(str(img_path), cv2.IMREAD_COLOR)            \n",
    "        img_HEIGHT, img_WIDTH = img_bgr.shape[:2]           \n",
    "\n",
    "        # Load masks and create coral mask.\n",
    "        mask_bleached = load_mask(mb_path, (img_HEIGHT, img_WIDTH))\n",
    "        mask_non_bleached = load_mask(mn_path, (img_HEIGHT, img_WIDTH))\n",
    "        all_coral_mask: npt.NDArray[np.bool_] = (mask_bleached | mask_non_bleached) if (mask_bleached is not None and mask_non_bleached is not None) else None          \n",
    "        if all_coral_mask is None or not all_coral_mask.any():\n",
    "            continue\n",
    "        \n",
    "        # Calculate all scores\n",
    "        _, _, raw_red_score, albedo_score, luminance_score, saturation_score = create_all_scores(img_bgr, all_coral_mask)\n",
    "\n",
    "\n",
    "        def get_ecdf(score: npt.NDArray[np.float32]) -> Tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "            # Initialize variables\n",
    "            nr_of_bins = 4096\n",
    "            bin_heights = np.zeros(nr_of_bins, dtype=np.float64)\n",
    "            bin_edges = None\n",
    "\n",
    "            # 1D matrix of whiteness scores, excludes 0 values of non coral pixels\n",
    "            score_flattened = score[all_coral_mask]  # coral-only 1D\n",
    "            if score_flattened.size == 0:\n",
    "                raise ValueError(f\"Empty score array detected.\")\n",
    "\n",
    "            # Values outside the winsor range get clipped to the nearst number in the range (to prevfent extreme points from dominating the histogram)\n",
    "            lo, hi = np.percentile(score_flattened, (0.05, 0.95))\n",
    "            score_flattened = np.clip(score_flattened, lo, hi)\n",
    "\n",
    "            # bin_edges stores the bin edges as an 1D array. \n",
    "            count, bin_edges = np.histogram(score_flattened, bins=nr_of_bins, range=(0.0, 1.0))\n",
    "\n",
    "            # Each image has the same influence on the ECDF. Big images will have the same influence as small images.\n",
    "            sum = count.sum()\n",
    "            if sum > 0:\n",
    "                bin_heights += count / sum\n",
    "\n",
    "            # Sum all histograms, and normalize to keep the whiteness scores in [0,1]\n",
    "            cdf = np.cumsum(bin_heights) / bin_heights.sum()\n",
    "            return (bin_edges, cdf)\n",
    "    \n",
    "    # Create separate ECDF for each score\n",
    "    raw_red_bin_edges, raw_red_cdf = get_ecdf(raw_red_score)\n",
    "    print(\"raw red done\")\n",
    "    albedo_bin_edges, albedo_cdf = get_ecdf(albedo_score)\n",
    "    print(\"albedo done\")\n",
    "    luminance_bin_edges, luminance_cdf = get_ecdf(luminance_score)\n",
    "    print(\"luminance done\")\n",
    "    saturation_bin_edges, saturation_cdf = get_ecdf(saturation_score)\n",
    "\n",
    "    # Save cdf and input values as a dictionary\n",
    "    return {\"raw_red_bin_edges\": raw_red_bin_edges, \"raw_red_cdf\": raw_red_cdf, \n",
    "            \"albedo_bin_edges\": albedo_bin_edges, \"albedo_cdf\": albedo_cdf, \n",
    "            \"luminance_bin_edges\": luminance_bin_edges, \"luminance_cdf\": luminance_cdf, \n",
    "            \"saturation_bin_edges\": saturation_bin_edges, \"saturation_cdf\": saturation_cdf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88d3719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = triple[:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
