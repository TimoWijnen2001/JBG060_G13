{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfaf8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timow\\Documents\\School\\GitHub\\JBG060_G13\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961d2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CoralSeg loaded: 4922 total samples\n",
      "       dataset  split                                         image_path  \\\n",
      "3968  CoralSeg    val  ..\\benthic_data\\Coralseg\\val\\Image\\FR5_6656_71...   \n",
      "1982  CoralSeg  train  ..\\benthic_data\\Coralseg\\train\\Image\\PAL69_972...   \n",
      "1098  CoralSeg  train  ..\\benthic_data\\Coralseg\\train\\Image\\PAL132_25...   \n",
      "\n",
      "                                              mask_path  \n",
      "3968  ..\\benthic_data\\Coralseg\\val\\Mask\\FR5_6656_716...  \n",
      "1982  ..\\benthic_data\\Coralseg\\train\\Mask\\PAL69_9728...  \n",
      "1098  ..\\benthic_data\\Coralseg\\train\\Mask\\PAL132_256...  \n"
     ]
    }
   ],
   "source": [
    "# === Section 2: Load CoralSeg Dataset ===\n",
    "\n",
    "BASE_PATH = \"..\\\\benthic_data\"\n",
    "CORALSEG_PATH = os.path.join(BASE_PATH, \"Coralseg\")\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "coralseg_data = []\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = os.path.join(CORALSEG_PATH, split, \"Image\")\n",
    "    mask_dir = os.path.join(CORALSEG_PATH, split, \"Mask\")\n",
    "\n",
    "    img_files = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")))\n",
    "    mask_files = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "\n",
    "    # Match by filename\n",
    "    for img_path in img_files:\n",
    "        fname = os.path.basename(img_path).replace(\".jpg\", \"\")\n",
    "        mask_path = os.path.join(mask_dir, fname + \".png\")\n",
    "        if os.path.exists(mask_path):\n",
    "            coralseg_data.append({\n",
    "                \"dataset\": \"CoralSeg\",\n",
    "                \"split\": split,\n",
    "                \"image_path\": img_path,\n",
    "                \"mask_path\": mask_path\n",
    "            })\n",
    "\n",
    "coralseg_df = pd.DataFrame(coralseg_data)\n",
    "print(f\"‚úÖ CoralSeg loaded: {len(coralseg_df)} total samples\")\n",
    "print(coralseg_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4dcb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing site: SEAFLOWER_BOLIVAR\n",
      "üìÇ Processing site: SEAFLOWER_COURTOWN\n",
      "üìÇ Processing site: SEAVIEW_ATL\n",
      "üìÇ Processing site: SEAVIEW_IDN_PHL\n",
      "üìÇ Processing site: SEAVIEW_PAC_AUS\n",
      "üìÇ Processing site: SEAVIEW_PAC_USA\n",
      "üìÇ Processing site: TETES_PROVIDENCIA\n",
      "üìÇ Processing site: UNAL_BLEACHING_TAYRONA\n",
      "‚úÖ reef_support loaded: 3311 samples across 8 sites\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b9a8c2e0-fd4f-4196-8280-50904fb75b9f",
       "rows": [
        [
         "769",
         "SEAVIEW_ATL",
         "train",
         "..\\benthic_data\\reef_support\\SEAVIEW_ATL\\images\\20021101501.jpg",
         "..\\benthic_data\\reef_support\\SEAVIEW_ATL\\masks_stitched\\20021101501_mask.png"
        ],
        [
         "1661",
         "SEAVIEW_PAC_AUS",
         "train",
         "..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\images\\10001026802.jpg",
         "..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\masks_stitched\\10001026802_mask.png"
        ],
        [
         "3307",
         "UNAL_BLEACHING_TAYRONA",
         "train",
         "..\\benthic_data\\reef_support\\UNAL_BLEACHING_TAYRONA\\images\\C9_PB_PSA_T3_19nov24_HBenavides_Corr.JPG",
         "..\\benthic_data\\reef_support\\UNAL_BLEACHING_TAYRONA\\masks_stitched\\C9_PB_PSA_T3_19nov24_HBenavides_Corr_mask.png"
        ],
        [
         "1893",
         "SEAVIEW_PAC_AUS",
         "train",
         "..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\images\\12012079802.jpg",
         "..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\masks_stitched\\12012079802_mask.png"
        ],
        [
         "1600",
         "SEAVIEW_IDN_PHL",
         "train",
         "..\\benthic_data\\reef_support\\SEAVIEW_IDN_PHL\\images\\33018102201.jpg",
         "..\\benthic_data\\reef_support\\SEAVIEW_IDN_PHL\\masks_stitched\\33018102201_mask.png"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>SEAVIEW_ATL</td>\n",
       "      <td>train</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_ATL\\image...</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_ATL\\masks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>SEAVIEW_PAC_AUS</td>\n",
       "      <td>train</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\i...</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>UNAL_BLEACHING_TAYRONA</td>\n",
       "      <td>train</td>\n",
       "      <td>..\\benthic_data\\reef_support\\UNAL_BLEACHING_TA...</td>\n",
       "      <td>..\\benthic_data\\reef_support\\UNAL_BLEACHING_TA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>SEAVIEW_PAC_AUS</td>\n",
       "      <td>train</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\i...</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>SEAVIEW_IDN_PHL</td>\n",
       "      <td>train</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_IDN_PHL\\i...</td>\n",
       "      <td>..\\benthic_data\\reef_support\\SEAVIEW_IDN_PHL\\m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dataset  split  \\\n",
       "769              SEAVIEW_ATL  train   \n",
       "1661         SEAVIEW_PAC_AUS  train   \n",
       "3307  UNAL_BLEACHING_TAYRONA  train   \n",
       "1893         SEAVIEW_PAC_AUS  train   \n",
       "1600         SEAVIEW_IDN_PHL  train   \n",
       "\n",
       "                                             image_path  \\\n",
       "769   ..\\benthic_data\\reef_support\\SEAVIEW_ATL\\image...   \n",
       "1661  ..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\i...   \n",
       "3307  ..\\benthic_data\\reef_support\\UNAL_BLEACHING_TA...   \n",
       "1893  ..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\i...   \n",
       "1600  ..\\benthic_data\\reef_support\\SEAVIEW_IDN_PHL\\i...   \n",
       "\n",
       "                                              mask_path  \n",
       "769   ..\\benthic_data\\reef_support\\SEAVIEW_ATL\\masks...  \n",
       "1661  ..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\m...  \n",
       "3307  ..\\benthic_data\\reef_support\\UNAL_BLEACHING_TA...  \n",
       "1893  ..\\benthic_data\\reef_support\\SEAVIEW_PAC_AUS\\m...  \n",
       "1600  ..\\benthic_data\\reef_support\\SEAVIEW_IDN_PHL\\m...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Section 3: Load reef_support datasets ===\n",
    "\n",
    "REEF_SUPPORT_PATH = os.path.join(BASE_PATH, \"reef_support\")\n",
    "\n",
    "reef_data = []\n",
    "\n",
    "# Loop through each reef site\n",
    "for site in sorted(os.listdir(REEF_SUPPORT_PATH)):\n",
    "    site_dir = os.path.join(REEF_SUPPORT_PATH, site)\n",
    "    img_dir = os.path.join(site_dir, \"images\")\n",
    "    stitched_dir = os.path.join(site_dir, \"masks_stitched\")\n",
    "    masks_dir = os.path.join(site_dir, \"masks\")\n",
    "\n",
    "    if not os.path.isdir(img_dir):\n",
    "        continue\n",
    "\n",
    "    print(f\"üìÇ Processing site: {site}\")\n",
    "\n",
    "    # Prefer stitched masks (cleaner)\n",
    "    stitched_masks = sorted(glob.glob(os.path.join(stitched_dir, \"*.png\")))\n",
    "    for mask_path in stitched_masks:\n",
    "        fname = os.path.basename(mask_path).replace(\"_mask.png\", \"\").replace(\".png\", \"\")\n",
    "        img_candidates = glob.glob(os.path.join(img_dir, f\"{fname}.*\"))\n",
    "        if len(img_candidates) == 0:\n",
    "            continue\n",
    "        img_path = img_candidates[0]\n",
    "\n",
    "        reef_data.append({\n",
    "            \"dataset\": site,\n",
    "            \"split\": \"train\",  # no official split, will randomize later\n",
    "            \"image_path\": img_path,\n",
    "            \"mask_path\": mask_path\n",
    "        })\n",
    "\n",
    "reef_df = pd.DataFrame(reef_data)\n",
    "print(f\"‚úÖ reef_support loaded: {len(reef_df)} samples across {reef_df['dataset'].nunique()} sites\")\n",
    "reef_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ca1694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3311/3311 [00:00<00:00, 5692.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4922/4922 [00:00<00:00, 32095.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final merged dataset size: 3276 samples\n",
      "dataset\n",
      "SEAFLOWER_BOLIVAR         245\n",
      "SEAFLOWER_COURTOWN        241\n",
      "SEAVIEW_ATL               651\n",
      "SEAVIEW_IDN_PHL           466\n",
      "SEAVIEW_PAC_AUS           657\n",
      "SEAVIEW_PAC_USA           276\n",
      "TETES_PROVIDENCIA         105\n",
      "UNAL_BLEACHING_TAYRONA    635\n",
      "dtype: int64\n",
      "üíæ Saved metadata to ../coral_project_outputs/merged_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAVE_UNION_DIR = \"../coral_project_outputs/union_masks\"\n",
    "os.makedirs(SAVE_UNION_DIR, exist_ok=True)\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "def make_union_mask(mask_dir, target_name):\n",
    "    \"\"\"Combine all *_mask_*.png files into one binary union mask.\"\"\"\n",
    "    masks = glob.glob(os.path.join(mask_dir, f\"{target_name}_mask_*.png\"))\n",
    "    if not masks:\n",
    "        return None\n",
    "\n",
    "    combined = None\n",
    "    for mpath in masks:\n",
    "        mask = cv2.imread(mpath, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            continue\n",
    "        mask = (mask > 0).astype(np.uint8)\n",
    "        combined = mask if combined is None else np.maximum(combined, mask)\n",
    "\n",
    "    if combined is None:\n",
    "        return None\n",
    "\n",
    "    save_path = os.path.join(SAVE_UNION_DIR, f\"{target_name}_union.png\")\n",
    "    cv2.imwrite(save_path, combined * 255)\n",
    "    return save_path\n",
    "\n",
    "# Process reef_support sites (including union masks)\n",
    "for _, row in tqdm(reef_df.iterrows(), total=len(reef_df)):\n",
    "    img_path = row[\"image_path\"]\n",
    "    site_dir = os.path.dirname(os.path.dirname(img_path))\n",
    "    masks_dir = os.path.join(site_dir, \"masks\")\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Try to create or find best mask\n",
    "    if os.path.exists(os.path.join(site_dir, \"masks_stitched\", f\"{fname}_mask.png\")):\n",
    "        mask_path = os.path.join(site_dir, \"masks_stitched\", f\"{fname}_mask.png\")\n",
    "    else:\n",
    "        mask_path = make_union_mask(masks_dir, fname)\n",
    "\n",
    "    if mask_path and os.path.exists(mask_path):\n",
    "        merged_data.append({\n",
    "            \"dataset\": row[\"dataset\"],\n",
    "            \"split\": \"train\",\n",
    "            \"image_path\": img_path,\n",
    "            \"mask_path\": mask_path\n",
    "        })\n",
    "\n",
    "# Add CoralSeg dataset\n",
    "for _, row in tqdm(coralseg_df.iterrows(), total=len(coralseg_df)):\n",
    "    merged_data.append({\n",
    "        \"dataset\": row[\"dataset\"],\n",
    "        \"split\": row[\"split\"],\n",
    "        \"image_path\": row[\"image_path\"],\n",
    "        \"mask_path\": row[\"mask_path\"]\n",
    "    })\n",
    "\n",
    "merged_df = pd.DataFrame(merged_data)\n",
    "\n",
    "# Clean ‚Äî remove empties\n",
    "def valid_mask(path):\n",
    "    if not os.path.exists(path):\n",
    "        return False\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return mask is not None and mask.sum() > 0\n",
    "\n",
    "merged_df = merged_df[merged_df[\"mask_path\"].apply(valid_mask)].reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Final merged dataset size: {len(merged_df)} samples\")\n",
    "print(merged_df.groupby(\"dataset\").size())\n",
    "\n",
    "# Save CSV metadata for reuse\n",
    "csv_path = \"../coral_project_outputs/merged_dataset.csv\"\n",
    "merged_df.to_csv(csv_path, index=False)\n",
    "print(f\"üíæ Saved metadata to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d614572",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmerged_df\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa41c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reloaded merged dataset: 3276 samples\n",
      "dataset\n",
      "SEAFLOWER_BOLIVAR         245\n",
      "SEAFLOWER_COURTOWN        241\n",
      "SEAVIEW_ATL               651\n",
      "SEAVIEW_IDN_PHL           466\n",
      "SEAVIEW_PAC_AUS           657\n",
      "SEAVIEW_PAC_USA           276\n",
      "TETES_PROVIDENCIA         105\n",
      "UNAL_BLEACHING_TAYRONA    635\n",
      "dtype: int64\n",
      "‚úÖ Random sample files verified\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"../coral_project_outputs/merged_dataset.csv\"\n",
    "\n",
    "merged_df = pd.read_csv(csv_path)\n",
    "print(f\"‚úÖ Reloaded merged dataset: {len(merged_df)} samples\")\n",
    "print(merged_df.groupby(\"dataset\").size())\n",
    "\n",
    "# Optional sanity check\n",
    "sample = merged_df.sample(3, random_state=42)\n",
    "for _, row in sample.iterrows():\n",
    "    assert os.path.exists(row[\"image_path\"]), f\"Missing image {row['image_path']}\"\n",
    "    assert os.path.exists(row[\"mask_path\"]), f\"Missing mask {row['mask_path']}\"\n",
    "print(\"‚úÖ Random sample files verified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f1f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Train: 2620 | Val: 656\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# -------------------\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(merged_df, test_size=0.2, random_state=42, stratify=None)\n",
    "print(f\"üìä Train: {len(train_df)} | Val: {len(val_df)}\")\n",
    "\n",
    "# -------------------\n",
    "# Augmentations\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# -------------------\n",
    "# Custom Dataset\n",
    "class CoralDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, \"image_path\"]\n",
    "        mask_path = self.df.loc[idx, \"mask_path\"]\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))  # grayscale\n",
    "        mask = (mask > 0).astype(np.float32)  # binary coral/non-coral\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"].unsqueeze(0)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034e6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------\n",
    "# Datasets & Dataloaders\n",
    "train_dataset = CoralDataset(train_df, transform=train_transform)\n",
    "val_dataset = CoralDataset(val_df, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# # -------------------\n",
    "# # Quick check\n",
    "# imgs, masks = next(iter(train_loader))\n",
    "# print(f\"‚úÖ Dataloader OK ‚Äî batch shapes: imgs {imgs.shape}, masks {masks.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5579a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"../coral_project_outputs/merged_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train:   0%|          | 0/655 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# === Section 6: Model setup and training (best config) ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# -------------------\n",
    "# Model\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "# -------------------\n",
    "# Loss: BCE + Dice combo\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "dice_loss = smp.losses.DiceLoss(mode=\"binary\")\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.5 * bce_loss(y_pred, y_true) + 0.5 * dice_loss(y_pred, y_true)\n",
    "\n",
    "# -------------------\n",
    "# Metrics\n",
    "def iou_score(y_pred, y_true, threshold=0.5):\n",
    "    y_pred_bin = (torch.sigmoid(y_pred) > threshold).float()\n",
    "    intersection = (y_pred_bin * y_true).sum()\n",
    "    union = y_pred_bin.sum() + y_true.sum() - intersection\n",
    "    return (intersection / union).item() if union > 0 else 1.0\n",
    "\n",
    "def pixel_accuracy(y_pred, y_true, threshold=0.5):\n",
    "    y_pred_bin = (torch.sigmoid(y_pred) > threshold).float()\n",
    "    correct = (y_pred_bin == y_true).float().sum()\n",
    "    total = torch.numel(y_true)\n",
    "    return (correct / total).item()\n",
    "\n",
    "# -------------------\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# -------------------\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=30, patience=5, save_path=\"../coral_project_outputs/best_merged_model.pth\"):\n",
    "    best_iou = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_iou, train_acc = 0, 0, 0\n",
    "\n",
    "        for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Train\"):\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_iou += iou_score(outputs, masks)\n",
    "            train_acc += pixel_accuracy(outputs, masks)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_iou, val_acc = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Val\"):\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                val_iou += iou_score(outputs, masks)\n",
    "                val_acc += pixel_accuracy(outputs, masks)\n",
    "\n",
    "        # Averages\n",
    "        train_loss /= len(train_loader)\n",
    "        train_iou /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_iou /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print(f\" Train Loss: {train_loss:.4f} | IoU: {train_iou:.4f} | Acc: {train_acc:.4f}\")\n",
    "        print(f\" Val   Loss: {val_loss:.4f} | IoU: {val_iou:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_iou > best_iou:\n",
    "            best_iou = val_iou\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"  ‚úÖ Saved new best model with IoU={best_iou:.4f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Training complete. Best IoU: {best_iou:.4f}\")\n",
    "    return model\n",
    "\n",
    "# -------------------\n",
    "# Run training\n",
    "final_model = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epochs=25,\n",
    "    patience=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ecff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# ===== Datasets & Dataloaders (optimized for CUDA in notebooks) =====\n",
    "import os, platform, time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "\n",
    "# Assumes: CoralDataset, train_df, val_df, train_transform, val_transform exist\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Prevent thread oversubscription (helps with OpenCV and albumentations)\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Throughput knobs (tune if needed)\n",
    "NUM_WORKERS = 2\n",
    "PERSISTENT = True\n",
    "PREFETCH   = 2\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def make_loader(df, transform, batch_size=BATCH_SIZE, shuffle=False):\n",
    "    return DataLoader(\n",
    "        dataset=CoralDataset(df, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,                 # benefit with CUDA when using non_blocking=True\n",
    "        drop_last=False,\n",
    "        persistent_workers=PERSISTENT,\n",
    "        prefetch_factor=PREFETCH,\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(train_df, train_transform, shuffle=True)\n",
    "val_loader   = make_loader(val_df,   val_transform,   shuffle=False)\n",
    "\n",
    "# (Optional) quick timing probe\n",
    "def time_first_batch(loader, label):\n",
    "    t0 = time.perf_counter()\n",
    "    it = iter(loader)\n",
    "    t1 = time.perf_counter()\n",
    "    batch = next(it)\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"[{label}] iter(): {(t1 - t0):.3f}s | first batch: {(t2 - t1):.3f}s\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "time_first_batch(train_loader, \"train\")\n",
    "time_first_batch(val_loader,   \"val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
